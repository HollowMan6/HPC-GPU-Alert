%!TEX root = ../Thesis.tex
\chapter{Conclusions and future work}
\label{chap:conclusions}
In this chapter, we critically analyze and interpret the findings presented in this thesis, focusing on their significance, implications, and potential applications. Then, we conclude with future work that we could not cover during the thesis period.

\section{Summary}

The thesis comprehensively explores designing, implementing, and evaluating a monitoring system and alert service for GPU resource utilization in High-Performance Computing (HPC) clusters. Through a systematic methodology, the research addresses critical challenges in efficiently analyzing jobs in HPC systems in real-time, focusing on minimizing alert delays and performance impacts on database systems, maintaining reliable data structures for job alert status checks, and identifying optimal algorithms for generating alerts, to address all research questions in Section \ref{sec:rqs}.

The thesis's contributions are multifaceted. First, a monitoring system and alert service are successfully created and deployed for Nvidia and AMD GPUs within Slurm-managed supercomputer systems. Then, an algorithm is developed to detect and alert jobs with inefficient GPU resource usage by investigating collected monitoring data. Additionally, the thesis provides insights into GPU resource utilization dynamics. It offers practical applications in advancing generative AI models while promoting sustainability in HPC cluster usage.

The thesis comprises sections dedicated to discussing techniques for building the monitoring system and alert service, detailing the implementation of the proposed system, presenting results from experimental benchmark and production setups, and offering concluding remarks. The methodology includes requirement analysis, system design and architecture, implementation and deployment, data collection and analysis, evaluation and validation, feedback and iterative improvement, documentation, and knowledge transfer.

The thesis illustrates the operationalization of the monitoring system and alert service through JSON strings and SQL code excerpts, showcasing the real-time mechanisms for capturing and processing job metadata and GPU usage data. Triggers and notification functions within the PostgreSQL database enable instantaneous communication and notification of relevant events, facilitating timely updates and actions based on incoming data.

Overall, the thesis contributes to advancing monitoring and alerting systems for GPU resource utilization in HPC clusters, with practical implications for optimizing job scheduling, resource allocation, and overall system efficiency. By addressing critical challenges and proposing innovative solutions, the research enhances the effectiveness and sustainability of GPU-accelerated computing environments, paving the way for future advancements in AI research and HPC infrastructure management.

\section{Future work}
There are several avenues for future research and improvements due to the limited time during this master's thesis project:

\begin{enumerate}
    \item \textbf{Integration with Additional Job Schedulers}: Extend support for real-time GPU monitoring to additional job schedulers commonly used in HPC environments, such as LSF \cite{10.1145/3569951.3597564}, TORQUE \cite{10.1145/1188455.1188464}, or UGE \cite{10.1145/3332186.3338408}, enhancing the compatibility with diverse cluster architectures.
    \item \textbf{More Monitoring Metrics}: Collect monitoring data from other hardware (e.g., CPU, disk I/O) and collectively contribute to the alert for the whole system. The monitoring infrastructure already has the capabilities for monitoring additional hardware, but they have not been tested in production due to performance considerations. In addition, we can also explore the possibility of capturing and analyzing fine-grained GPU usage metrics, including memory bandwidth, cache utilization, and instruction throughput. This granular level of monitoring can provide deeper insights into application performance and identify optimization opportunities at the code level.
    \item \textbf{Flexible Alerting}: Investigate adaptive alerting strategies that dynamically adjust thresholds we use in the alert algorithms currently based on workload characteristics, ensuring effective alerting across varying HPC workloads. It's also worth exploring the integration of possible other advanced machine learning algorithms to predict GPU resource usage patterns, enabling proactive alerting based on historical data analysis. We can also try to implement mechanisms to directly gather feedback from administrators or support teams regarding the effectiveness of the jobs, and improve our alert strategies automatically, so that we can have continuous refinement based on practical usage experiences.
    % Publish hints to HPC users regarding how to fix and improve their job utilization of hardware resources.
    \item \textbf{Resource Optimization}: Investigate optimization techniques for dynamically allocating GPU resources based on real-time workload demands and system utilization. This could involve developing algorithms for intelligent resource provisioning and load balancing to maximize overall cluster efficiency and performance. We can also investigate the predictive maintenance techniques for GPUs based on real-time monitoring data. Predictive maintenance models can anticipate failures or performance degradation by analyzing hardware health metrics and performance degradation, enabling proactive maintenance actions to minimize downtime and maximize system reliability. It's also worth investigating integrating the real-time GPU monitoring system with energy management systems to optimize power consumption and reduce environmental impact. By correlating GPU usage metrics with power consumption data, HPC administrators can implement energy-efficient computing strategies, such as dynamic voltage and frequency scaling, to minimize power consumption without sacrificing performance.
\end{enumerate}
